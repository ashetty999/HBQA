{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7Jk6PcR3_yN"
      },
      "source": [
        "# Creating Vector Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If we run this machine on GPU machine it will be faster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xYSr9rKw4yf9"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "apipath = r'H:\\\\My Drive\\\\config\\\\hbqa.txt'\n",
        "import configparser\n",
        "\n",
        "config = configparser.ConfigParser()\n",
        "config.read(apipath)\n",
        "secret_key = config['global']['OPENAI_API_KEY']\n",
        "datapath = config['global']['DATA_FOLDER']\n",
        "corpuspath = config['global']['CORPUS_FOLDER']\n",
        "PINECONE_API_KEY = config['global']['PINECONE_API_KEY']\n",
        "PINECONE_ENV = config['global']['PINECONE_ENV']\n",
        "\n",
        "# PINECONE is Vector Database. To store the vector so that we can quickly search the vector space.\n",
        "# https://app.pinecone.io\n",
        "# get PINECONE_API_KEY key from app.pinecone.io\n",
        "# find your PINECONE_ENVIRONMENT next to the api key in pinecone console"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Creating Embedding for Chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(256, 7)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Context_Len</th>\n",
              "      <th>Len</th>\n",
              "      <th>Section_Id</th>\n",
              "      <th>Chunk_Id</th>\n",
              "      <th>Prompt</th>\n",
              "      <th>Chunk</th>\n",
              "      <th>QA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000</td>\n",
              "      <td>2030</td>\n",
              "      <td>Book01_046</td>\n",
              "      <td>193</td>\n",
              "      <td>Write 1 question, corresponding answer, and th...</td>\n",
              "      <td>Sauti continued, 'The Muni, having said so unt...</td>\n",
              "      <td>\\nQ1: Why did the Muni wander over the earth a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2000</td>\n",
              "      <td>3462</td>\n",
              "      <td>Book01_104</td>\n",
              "      <td>425</td>\n",
              "      <td>Write 6 question, corresponding answer, and th...</td>\n",
              "      <td>In this connection there is another old histor...</td>\n",
              "      <td>Q1: Who was the wise Rishi mentioned in the te...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2000</td>\n",
              "      <td>1974</td>\n",
              "      <td>Book01_007</td>\n",
              "      <td>83</td>\n",
              "      <td>Write 1 question, corresponding answer, and th...</td>\n",
              "      <td>Sauti said, 'the god of fire enraged at the cu...</td>\n",
              "      <td>Q1: What did Agni say was the consequence of a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2000</td>\n",
              "      <td>1492</td>\n",
              "      <td>Book01_005</td>\n",
              "      <td>78</td>\n",
              "      <td>Write 1 question, corresponding answer, and th...</td>\n",
              "      <td>And the Rakshasa saw the apartment in which th...</td>\n",
              "      <td>Q1: What did the Rakshasa ask the god of fire ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Context_Len   Len  Section_Id  Chunk_Id  \\\n",
              "0         2000  2030  Book01_046       193   \n",
              "1         2000  3462  Book01_104       425   \n",
              "2         2000  1974  Book01_007        83   \n",
              "3         2000  1492  Book01_005        78   \n",
              "\n",
              "                                              Prompt  \\\n",
              "0  Write 1 question, corresponding answer, and th...   \n",
              "1  Write 6 question, corresponding answer, and th...   \n",
              "2  Write 1 question, corresponding answer, and th...   \n",
              "3  Write 1 question, corresponding answer, and th...   \n",
              "\n",
              "                                               Chunk  \\\n",
              "0  Sauti continued, 'The Muni, having said so unt...   \n",
              "1  In this connection there is another old histor...   \n",
              "2  Sauti said, 'the god of fire enraged at the cu...   \n",
              "3  And the Rakshasa saw the apartment in which th...   \n",
              "\n",
              "                                                  QA  \n",
              "0  \\nQ1: Why did the Muni wander over the earth a...  \n",
              "1  Q1: Who was the wise Rishi mentioned in the te...  \n",
              "2  Q1: What did Agni say was the consequence of a...  \n",
              "3  Q1: What did the Rakshasa ask the god of fire ...  "
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# This chunk was created to use with ChatGPT Front End to create prompt for generating QA.\n",
        "# At this point of time there was no clarity around chunk size, number of question, types of question, \\\n",
        "# as per initial investigation cost of ChatGPT API was very high. So intially this Chunk was created. \\\n",
        "# Unfortuntely the main file is lost. But the prompt created from those chunks still exists. So, after\\\n",
        "#  reverse engineering, created Chunk from the Prompt text.\n",
        "df_hbqa_for_fe = pd.read_csv(datapath+\"05-QA_Final_ChatGPT_FE-Created-14Sep23.csv\")\n",
        "print(df_hbqa_for_fe.shape)\n",
        "df_hbqa_for_fe.head(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# There are 256 chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(1963, 7)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Section_Id</th>\n",
              "      <th>Chunk_Id</th>\n",
              "      <th>Chunk</th>\n",
              "      <th>Chunk_Letters</th>\n",
              "      <th>Chunk_Words</th>\n",
              "      <th>Chunk_Approx_Tokens</th>\n",
              "      <th>Approx_Ques</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Book01_002</td>\n",
              "      <td>1</td>\n",
              "      <td>THE MAHABHARATA ADI PARVA Section I\\nOm! Havin...</td>\n",
              "      <td>7511</td>\n",
              "      <td>1214</td>\n",
              "      <td>1615.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Book01_002</td>\n",
              "      <td>2</td>\n",
              "      <td>The Rishi Vyasa published this mass of knowled...</td>\n",
              "      <td>7551</td>\n",
              "      <td>1261</td>\n",
              "      <td>1677.0</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Book01_002</td>\n",
              "      <td>3</td>\n",
              "      <td>Vyasa executed the compilation of the Bharata,...</td>\n",
              "      <td>6986</td>\n",
              "      <td>1162</td>\n",
              "      <td>1545.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Book01_002</td>\n",
              "      <td>5</td>\n",
              "      <td>'When I heard that Yudhishthira had been follo...</td>\n",
              "      <td>10832</td>\n",
              "      <td>1949</td>\n",
              "      <td>2592.0</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Section_Id  Chunk_Id                                              Chunk  \\\n",
              "0  Book01_002         1  THE MAHABHARATA ADI PARVA Section I\\nOm! Havin...   \n",
              "1  Book01_002         2  The Rishi Vyasa published this mass of knowled...   \n",
              "2  Book01_002         3  Vyasa executed the compilation of the Bharata,...   \n",
              "3  Book01_002         5  'When I heard that Yudhishthira had been follo...   \n",
              "\n",
              "   Chunk_Letters  Chunk_Words  Chunk_Approx_Tokens  Approx_Ques  \n",
              "0           7511         1214               1615.0            4  \n",
              "1           7551         1261               1677.0            5  \n",
              "2           6986         1162               1545.0            4  \n",
              "3          10832         1949               2592.0            7  "
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#This chunk was created to use with ChatGPT API to create prompt for QA. \n",
        "df_hbqa_for_api = pd.read_csv(datapath+\"03-Chunked_Book.csv\")\n",
        "print(df_hbqa_for_api.shape)\n",
        "df_hbqa_for_api.head(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# There are 1963 chunks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Both chunk files were created with different chapters of Mahabharat Book, different chunk size, they are created \n",
        "# at different time therefore chunk_id in \n",
        "# the both the files will be duplicate. To avoid that problem we are manually changing chunk_id\n",
        "df_hbqa_for_fe['Chunk_Id'] = df_hbqa_for_fe['Chunk_Id']+10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_mahabharat_chunk = pd.concat([df_hbqa_for_api[['Chunk_Id','Chunk']],\n",
        "df_hbqa_for_fe[['Chunk_Id','Chunk']]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(2219, 2)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Chunk_Id</th>\n",
              "      <th>Chunk</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1780</th>\n",
              "      <td>2567</td>\n",
              "      <td>and diamonds, as also with an altar constructe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1321</th>\n",
              "      <td>1977</td>\n",
              "      <td>Section CI\\n\"Yudhishthira said, 'Of what dispo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186</th>\n",
              "      <td>10277</td>\n",
              "      <td>Vaisampayana said, 'O king, they are as follow...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1755</th>\n",
              "      <td>2537</td>\n",
              "      <td>Section XCIII\\n  \"Yudhishthira said, 'If Brahm...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>886</th>\n",
              "      <td>1362</td>\n",
              "      <td>Section LXXVIII\\n\"Sanjaya said, 'Hearing these...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Chunk_Id                                              Chunk\n",
              "1780      2567  and diamonds, as also with an altar constructe...\n",
              "1321      1977  Section CI\\n\"Yudhishthira said, 'Of what dispo...\n",
              "186      10277  Vaisampayana said, 'O king, they are as follow...\n",
              "1755      2537  Section XCIII\\n  \"Yudhishthira said, 'If Brahm...\n",
              "886       1362  Section LXXVIII\\n\"Sanjaya said, 'Hearing these..."
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(df_mahabharat_chunk.shape)\n",
        "df_mahabharat_chunk.sample(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_mahabharat_chunk.to_csv(datapath+'08.1-Mahabharat_Chunk.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "-_AzjoAR3YTq"
      },
      "outputs": [],
      "source": [
        "# !pip install -U sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "3s_aEBvr3dOX"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\hari_\\anaconda3\\envs\\hbqa\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%time\n",
        "Chunk_Sentences = df_mahabharat_chunk.Chunk.tolist()\n",
        "Chunk_Embeddings = model.encode(Chunk_Sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "DEVICE='gpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "5K5tQT5m3hwz"
      },
      "outputs": [],
      "source": [
        "ChunkVectors= torch.tensor(Chunk_Embeddings, dtype=torch.float).to(DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "IfFH7ppc3j5t"
      },
      "outputs": [],
      "source": [
        "# Flatten the tensors into 1D arrays\n",
        "ChunkVec_list = ChunkVectors.tolist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_mahabharat_chunk['ChunkVector'] = ChunkVectors.tolist()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install pinecone-client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pinecone      \n",
        "\n",
        "pinecone.init(      \n",
        "\tapi_key='ddf2ef12-9108-4e80-b438-8f86a0b617c0',      \n",
        "\tenvironment='asia-southeast1-gcp-free'      \n",
        ")      \n",
        "index = pinecone.Index('HBQA')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pinecone\n",
        "\n",
        "# # get api key from app.pinecone.io\n",
        "# PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY') or 'PINECONE_API_KEY'\n",
        "# # find your environment next to the api key in pinecone console\n",
        "# PINECONE_ENV = os.environ.get('PINECONE_ENVIRONMENT') or 'PINECONE_ENVIRONMENT'\n",
        "\n",
        "pinecone.init(\n",
        "    api_key=PINECONE_API_KEY,\n",
        "    environment=PINECONE_ENV\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# index_name = 'semantic-search-fast'\n",
        "index_name = \"HBQA\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall pinecone_datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pinecone_datasets'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[27], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpinecone_datasets\u001b[39;00m \u001b[39mimport\u001b[39;00m load_dataset\n\u001b[0;32m      3\u001b[0m dataset \u001b[39m=\u001b[39m load_dataset(\u001b[39m'\u001b[39m\u001b[39mquora_all-MiniLM-L6-bm25\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[39m# # we drop sparse_values as they are not needed for this example\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[39m# dataset.documents.drop(['metadata'], axis=1, inplace=True)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[39m# dataset.documents.rename(columns={'blob': 'metadata'}, inplace=True)\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[39m# dataset.documents.drop(dataset.documents.index[:240_000], inplace=True)\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[39m# dataset.head()\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pinecone_datasets'"
          ]
        }
      ],
      "source": [
        "from pinecone_datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset('quora_all-MiniLM-L6-bm25')\n",
        "# # we drop sparse_values as they are not needed for this example\n",
        "# dataset.documents.drop(['metadata'], axis=1, inplace=True)\n",
        "# dataset.documents.rename(columns={'blob': 'metadata'}, inplace=True)\n",
        "# # we will use 80K rows of the dataset between rows 240K -> 320K\n",
        "# dataset.documents.drop(dataset.documents.index[320_000:], inplace=True)\n",
        "# dataset.documents.drop(dataset.documents.index[:240_000], inplace=True)\n",
        "# dataset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "# only create index if it doesn't exist\n",
        "if index_name not in pinecone.list_indexes():\n",
        "    pinecone.create_index(\n",
        "        name=index_name,\n",
        "        dimension=len(dataset.documents.iloc[0]['values']),\n",
        "        metric='cosine'\n",
        "    )\n",
        "    # wait a moment for the index to be fully initialized\n",
        "    time.sleep(1)\n",
        "\n",
        "# now connect to the index\n",
        "index = pinecone.GRPCIndex(index_name)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
